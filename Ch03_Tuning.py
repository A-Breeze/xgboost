# Extreme Gradient Boosting with XGBoost - DataCamp - January 2020
# Ch3: Fine-tuning XGBoost models

# -------------------------------------
# ---- Setup ----
# Import built-in modules
import warnings

# Import external modules
import xgboost as xgb
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import __version__ as mpl_version
from pyprojroot import here
from sklearn import __version__ as skl_version
from sklearn.model_selection import train_test_split  # For sklearn API examples

# Check they have imported OK
print("xgboost version: " + str(xgb.__version__))
print("numpy version: " + str(np.__version__))
print("pandas version: " + str(pd.__version__))
print("matplotlib version: " + str(mpl_version))
print("sklearn version: " + str(skl_version))

# Project locations
data_folder_path = here('.') / 'data'

# -------------------------------------
# ---- Notes ----
# TODO: Write notes
''' 
'''

# -------------------------------------
# ---- Ex01: TBA ----
# TODO: Write example
